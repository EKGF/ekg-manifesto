{"config":{"lang":["en"],"separator":"[\\s\\-]+"},"docs":[{"title":"Manifesto","text":"Values &amp; IdealsAll Data ConnectedStandardsData MarketsOpen WorldNotes   <ol> <li>Much higher levels of transparency, openness,    sustainability, fairness and    accountability are going to be required at all levels    in any organization or ecosystem.</li> <li>Human Capital needs to be known, valued, leveraged and optimized.</li> <li>Data Capital needs to be known, valued, leveraged and optimized.</li> <li>Increasing competitiveness depends more and more on having the     highest quality and depth of data, information and knowledge.</li> <li>Having one \"censored\", biased, Single version of the Truth (SVOT)    is no longer good enough for many---if not most---use cases in     most domains.</li> <li>The world becomes more and more polarised due to     \"information bubbles\" that many people are not escaping    from, more depth, context and connectedness is needed. </li> <li>The world becomes more and more complex and harder to understand,     a holistic view around every given topic, showing all viewpoints,    would provide people---and AI's---with deeper understanding enabling    them to make better decisions.</li> <li>Reusability of deliverables, components, artefacts, data, information,    knowledge and logic needs to effectively be the highest priority since    it positively affects all of the above.</li> </ol>   <ol> <li>All data that can be connected, will be connected.<ul> <li>Information, Knowledge, Meaning, Logic: it's all data.</li> <li>Knowledge &amp; Meaning will be captured as machine-readable executable    models.</li> <li>All your connected data is an EKG.</li> </ul> </li> <li>All data will be made available anywhere\u2014secured and within entitlement    limits\u2014at any time to any device, node or edge.<ul> <li>We embrace the Open World and deal with the realities of   Multiple versions of the Truth (MVOT).<ul> <li>PS: Open World does not mean that all data is open to everyone</li> </ul> </li> <li>Leveraging all processing power and storage capacity that is available at the edge</li> <li>Reducing energy consumption</li> </ul> </li> <li>We combine the digital footprint of activities along with a     digital representation of information and knowledge, from which     an EKG emerges.</li> <li>An EKG is connections of Knowledge Graphs across an Enterprise,    an Ecosystem or beyond.    See principle 3: Distributed.</li> <li>We encourage the use and widespread proliferation of     EKG identifiers (see principle 1: Identity)</li> </ol>   <ol> <li>EKGs are based on standards and therefore interoperable across boundaries.</li> <li>There are many types of standards that an EKG needs to be able to deal with.</li> <li>Standards are described as machine-readable models\u2014i.e. ontologies\u2014that     EKG Platforms can execute, interpret or enforce.</li> </ol> <p>See also principle 10: Standards.</p>   <ol> <li>Any data source will be turned into a data publisher---or supplier---of one or more s    self-describing datasets.<ul> <li>Any data sink will be turned into a data consumer, consuming one or more datasets.</li> </ul> </li> <li>Data suppliers and consumers will find each other via a data market using a     standard \"lingua franca\" for the data itself, its meaning, all its associated policies    and metadata and especially also its use cases as executable models.</li> <li>The data market manages the information supply chains between all the various suppliers and consumers.</li> <li>The global data market will consist of many other more specific data markets    e.g. per industry or per enterprise.</li> <li>An EKG is the combination of one or more data markets and the deployment of its use cases.</li> </ol>   <ol> <li>For any given \"Thing\"---i.e. an object\u2014there may be many representations in many datasets.</li> <li>An object's representations may be different in shape, meaning, timeliness, relevance and    quality---i.e. any given representation of information about a given object may represent     a different version of the truth.</li> <li>All representations of any given object shall be linked via shared identifiers.<ul> <li>Identifiers shall be meaningless, opaque, web-resolvable and universally unique.   See principle 1.</li> <li>An object can have multiple identifiers.</li> </ul> </li> <li>Any given object consists of 1 or more datapoints.</li> <li>A datapoint represents a logical property of a given object.<ul> <li>The identifier for a datapoint is the identifier of the object it belongs to plus at least one   identifier of the axiom that describes its meaning (which is also an object).</li> </ul> </li> <li>Datapoints---or datapoint-values for the same object---can exist in many datasets. <ul> <li>with potentially multiple versions of the truth in terms of meaning,   timeliness, relevance and quality.</li> </ul> </li> <li>Any representation for any given datapoint of any data source shall be     made available to any device, node or edge in the network within legal,     policy and entitlement limits in real-time.</li> <li>Every \"object\" or \"thing\" that is represented as data in whichever dataset anywhere,     shall have an identifier that is universally unique, permanent, meaningless    or opaque and therefore shareable, resolvable through the HTTP protocol.    See principle 1.</li> </ol> <p>See also principle 4: Open World.</p>   <p>Work in progress notes: that add more explanation to the above:</p> <ol> <li>Data will be considered explained when its usage has no misconceptions nor ambiguities.</li> <li>The word \u201cdata\u201d has a lot of different notions associated with it. We have these statements above, like \u201call data is connected\u201d, \u201c\u2026data will be made available anywhere\u2026\u201d, which could reinforce a particular notion that data is something that \u201cexists\u201d all around us, like a digital footprint of activities. On top of these statements on \u201cdata\u201d, the EKG is introduced as a combination of one or more data markets, which could further reinforce that \"EKG is connected data\". If that\u2019s the notion that the manifesto wants to declare, it may appeal strongly to some sections more than others, like those dealing with consolidation, analysis, reporting, verification etc. If the manifesto\u2019s intent is broader (here, I am very conscious of Carl\u2019s note that it should stay away from any hubris!) it would help if there is a way to declare that information and knowledge is also data. And it is when we combine the digital footprint of activities along with a digital representation of information and knowledge, that a Knowledge Graph emerges. And on top of that notion, an Enterprise Knowledge Graph is connections of Knowledge Graphs across an Enterprise. The intent of the above is to appeal broadly to different sections of an Enterprise, accommodating different norms and notions (again referring to Carl\u2019s insightful comment on Norms and Notions)</li> </ol>","location":""},{"title":"Mapping to the FAIR principles","text":"<p>The FAIR principles are a popular set of principles used by many Knowledge Graph practitioners.</p> F - FindableA - AccessibleI - InteroperableR - Reusable    <ul> <li> <p>FAIR Definition</p> <ul> <li>F1 -- (Meta)data are assigned a globally unique and persistent identifier</li> <li>F2 -- Data are described with rich metadata (defined by R1 below)</li> <li>F3 -- Metadata clearly and explicitly include the identifier of the data they describe</li> <li>F4 -- (Meta)data are registered or indexed in a searchable resource</li> </ul> </li> <li> <p>Differences</p> <p>EKG Principles are slightly more specific or prescriptive:</p> <ul> <li>Metadata (objects) and data (objects) can potentially have multiple identifiers (but at least one).</li> <li>Those identifiers do not necessarily be \"persistent\" as long as they are (always) resolvable (through HTTP).</li> <li>The EKG identifiers (EKG/IRIs) of data objects (but not necessarily metadata objects) should be   \"opaque\" as in \"meaningless\", (relatively) safe to be emailed around, stored in other platforms,   maximising \"proliferation\".</li> <li>FAIR principle F3 would be phrased the other way around: the data described by metadata refers to it via   the metadata identifier (i.e. the predicate-IRI).</li> <li>FAIR principle F4 slightly differs as well, the EKG Principles require metadata to be directly   resolvable (via HTTP) machine-readable definitions of the semantics in verifiable formal logic   (preferably OWL 2).</li> </ul> </li> </ul>     <ul> <li> <p>FAIR Definition</p> <p>Once the user finds the required data, they need to know how they can be accessed,  possibly including authentication and authorisation.</p> <ul> <li>A1 -- (Meta)data are retrievable by their identifier using a standardized communications protocol</li> <li>A1.1 -- The protocol is open, free, and universally implementable</li> <li>A1.2 -- The protocol allows for an authentication and authorisation procedure, where necessary</li> <li>A2 -- Metadata are accessible, even when the data are no longer available</li> </ul> </li> <li> <p>Differences</p> <p>EKG Principles are slightly more specific or prescriptive:</p> <ul> <li>\"using a standardized communications protocol\" would be explicitly the HTTP protocol    (or actually HTTPS/TLS) as a minimum requirement and in addition to that any other protocol,     standardized or not.</li> <li>\"metadata are accessible\" would be more explicit for the EKG:     all metadata has to be accessible through IRIs that are always \"resolvable\" via the HTTP protocol.    In other words, make sure that all your OWL 2 ontologies or RDF Schema (RDFS)     vocabularies are placed on highly available durable infrastructure that can always be accessed via HTTP.</li> </ul> </li> </ul>     <ul> <li> <p>FAIR Definition</p> <p>The data usually need to be integrated with other data.  In addition, the data need to interoperate with applications or workflows for analysis, storage, and processing.</p> <ul> <li>I1 -- (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.</li> <li>I2 -- (Meta)data use vocabularies that follow FAIR principles</li> <li>I3 -- (Meta)data include qualified references to other (meta)data</li> </ul> </li> <li> <p>Differences</p> <p>EKG Principles are slightly more specific or prescriptive:</p> <ul> <li>In the EKG the metadata that describes meaning i.e. the semantics    (there are also many other types of metadata) that     formal and broadly applicable language for knowledge representation    has to be preferably OWL 2 or at least RDF Schema (RDFS) or SHACL.</li> </ul> </li> </ul>     <ul> <li> <p>FAIR Definition</p> <p>The ultimate goal of FAIR is to optimise the reuse of data. To achieve this, metadata and data should be well-described so that they can be replicated and/or combined in different settings.</p> <ul> <li>R1 -- Meta(data) are richly described with a plurality of accurate and relevant attributes</li> <li>R1.1 -- (Meta)data are released with a clear and accessible data usage license</li> <li>R1.2 -- (Meta)data are associated with detailed provenance</li> <li>R1.3 -- (Meta)data meet domain-relevant community standards</li> </ul> <p>The principles refer to three types of entities: data (or any digital object), metadata (information about that digital object), and infrastructure. For instance, principle F4 defines that both metadata and data are registered or indexed in a searchable resource (the infrastructure component).</p> </li> <li> <p>Differences</p> <p>EKG Principles are slightly more specific or prescriptive:</p> <ul> <li>optimization of the reuse of data is the ultimate goal.    It's an important goal for EKG as well but reuse of knowledge and whole   use cases---with everything that comes with it---is an even higher level goal.   Furthermore, overall connectedness of all data and knowledge is an equally important goal.</li> <li>metadata and data should be well-described but should also be as \"unbiased\" as possible, not designed   for one particular (set of) use case(s) but designed to represent the version of the truth that a given data   source provides with the highest level of integrity.   See principle 5 -- Self-describing.</li> <li>Meta(data) are richly described with a plurality of accurate and relevant attributes.   \"Richly described\" would not be specific enough for EKG.   It would have to be directly resolvable to a machine-readable definition in verifiable formal logic.</li> <li>For all types of recognized metadata, which is metadata that services of the various EKG platforms can   recognize, the EKGF will specify accepted standards or define standards itself or in   collaboration with partners like the OMG.   Since an EKG is a collection of self-describing datasets, each dataset will have its    various types of metadata organized in a structured way.</li> </ul> </li> </ul>","location":"fair/"},{"title":"Other","text":"<p>The Enterprise Knowledge Graph Foundation is working on multiple initiatives that have lead to various websites:</p>","location":"other/"},{"title":"ekgf.org","text":"<p>The main website of the Foundation: https://ekgf.org</p>","location":"other/#ekgforg"},{"title":"Principles","text":"<p>The EKG/Principles:  https://principles.ekgf.org,  this is a project that is being maintained in the GitHub repository  EKGF/principles.</p> <p>You're welcome to contribute.</p>","location":"other/#principles"},{"title":"Maturity Model","text":"<p>The Maturity Model for the Enterprise Knowledge Graph:  https://maturity.ekgf.org, this is a project that is being maintained in the GitHub repository  EKGF/ekg-mm.</p> <p>You're welcome to contribute.</p>","location":"other/#maturity-model"},{"title":"Catalog","text":"<p>All use cases from the community, their datasets and their ontologies: https://catalog.ekgf.org</p>","location":"other/#catalog"},{"title":"Use Case Tree Method","text":"<p>A proposal for a front-to-back method to support your EKG journey: https://method.ekgf.org, this is a project that is being maintained in the GitHub repository EKGF/ekg-method.</p> <p>You're welcome to contribute.</p>","location":"other/#use-case-tree-method"},{"title":"EKG Principles","text":"Intro10 PrinciplesList   <p>These principles are intended to provide guidelines for the development and deployment of an Enterprise Knowledge Graph (EKG). </p> <p>The principles emphasize shared meaning and content reuse that are the cornerstone of operating in complex and interconnected environments.</p> <p>An enterprise that complies with all ten principles has an Enterprise Knowledge Graph.</p>    <ul> <li> <p> 1 - Identity</p>  <p>Any object in the EKG is identified with at least one universally unique, opaque,  permanent, non-reassignable and web-resolvable identifier in the form of an  International Resource Identifier (IRI) for the EKG---i.e. an Enterprise Knowledge Graph  IRI (EKG/IRI) aka EKG Identifier.</p> <p>  Learn more</p> </li> <li> <p> 2 - Meaning</p>  <p>The meaning of every Data Point must be directly resolvable  to a machine-readable definition in verifiable formal logic.</p> <p>  Learn more</p> </li> <li> <p> 3 - Distributed</p>  <p>Data Points for any object may be stored in many physical stores.  Any access point provides connectivity to all EKG content regardless of where it resides.</p> <p>  Learn more</p> </li> <li> <p> 4 - Open World</p>  <p>Information can vary over time, come from many internal and external sources,  and be based on different identifiers and models.  These multiple versions of the truth (MVOT) need to be reconciled on access by context.</p> <p>  Learn more</p> </li> <li> <p> 5 - Self-describing</p>  <p>An EKG is composed of a set of self-describing datasets (SDDs) that provide  information about lineage, provenance, pedigree, maturity, quality,  licensing and governance.</p> <p>  Learn more</p> </li> <li> <p> 6 - Measurement</p>  <p>The quality and characteristics of the managed knowledge must be measurable and measured.  Measurement criteria are used to designate fitness-for-defined-purpose and must be actionable.</p> <p>  Learn more</p> </li> <li> <p> 7 - Business Orientation</p>  <p>All information in the EKG, and associated artifacts, are linked to defined and  prioritized use cases.  Nothing in the EKG exists without a known business justification and purpose.</p> <p>  Learn more</p> </li> <li> <p> 8 - Control</p>  <p>Entitlement, privacy and business policies will be modeled in the EKG  and automatically executed, enforced and audited at the Data Point level.</p> <p>  Learn more</p> </li> <li> <p> 9 - Ecosystem</p>  <p>An enterprise will use a heterogeneous set of technologies and data sources which  will be incorporated into the EKG over time.  All data entering the ecosystem are subject to service level agreements.</p> <p>  Learn more</p> </li> <li> <p> 10 - Standards</p>  <p>Data, ontologies, definitions and business rules should be compliant with open  standards and transparent governance procedures as defined by recognized standards  bodies.</p> <p>  Learn more</p> </li> </ul>        Principle Summary     1. Identity Any given object is identified with at least one universally unique, opaque, permanent, and web-resolvable identifier.   2. Meaning The meaning of every data point must be directly resolvable to a machine-readable mathematical definition.   3. Distributed An EKG can incorporate any number of datasets of any number of data sources that can be hosted by any number of independent EKG Platforms. Any given access point provides connectivity to the EKG regardless of where it resides.   4. Open World Information can vary over time, come from many internal and external sources, and be based on different identities and models.  These \u201cmultiple versions of the truth\u201d need to be reconciled on access by context.   5. Self-describing An EKG is composed of a set of self-describing datasets that provide information about lineage, provenance, pedigree, maturity, quality, and governance. The EKG Platform has policy enforcement services that are driven by these self-describing datasets.   6. Measurement The quality and characteristics of the managed knowledge must be measurable and measured.  Measurement criteria are used to designate fitness-for-defined-purpose and must be actionable.   7. Business Orientation All artifacts around and information in the EKG are linked to defined and prioritized use cases.  Nothing in the EKG exists without a known business justification and purpose.   8. Control Entitlement, privacy, and business policies will be modeled in the EKG and automatically executed, enforced, and audited at the data point level.   9. Ecosystem An enterprise will use a heterogeneous set of technologies and data sources that will be incorporated into the EKG over time.   All components of the ecosystem are subject to service level agreements.   10. Standards Both the EKG Platform and knowledge content should be based on open standards. Where necessary, the EKG Foundation will work to expand those standards.","location":"principle/"},{"title":"Identity","text":"<p>Any object in the EKG is identified with at least one universally unique, opaque, permanent, non-reassignable and web-resolvable identifier in the form of an International Resource Identifier (IRI) for the EKG---i.e. an Enterprise Knowledge Graph IRI (EKG/IRI) aka EKG Identifier.</p>  <p>As said, the EKG/IRI identifier is permanent, will be proliferated across the enterprise's universe---including its ecosystem---and will be used for the expression of facts about the object including relationships between objects.</p> <p>Additional non-EKG identifiers may also be assigned, and they may be human-readable, \"external\" to the enterprise's EKG and be transient and reassignable.</p> <p>Resolving an identifier can be done in three ways:</p> <ol> <li>using it in a transaction---i.e. a query or update statement---submitted or routed via an    internet protocol to a \"lookup service\" that translates one or more given \"features\" of an    object to an EKG/IRI.</li> <li>constructing it via a standardized policy from key components and applying a hash and optionally    signing it---where the object represented by the EKG/IRI may or may not already exist.</li> <li>constructing it by giving the object an EKG/IRI based on a random number in case the EKG is    the authoritative source for the given object.</li> </ol>","location":"principle/01-identity/"},{"title":"Rationale","text":"<p>While the semantic web technologies---like for instance RDF---generally allow for many and varied IRIs, and this is still encouraged when integrating systems, there is benefit in being able to rely on one canonical and unchanging one, which can for example make the mapping of identities a many-to-one rather than a many-to-many task.</p> <p>In addition to that, to enhance the likelihood that various EKGs, or smaller Knowledge Graphs within an EKG---across departments, organizations or ecosystems---can interoperate easily with each other, the use of standardized EKG/IRIs needs to be encouraged since various EKGs can come to the same identifiers independently, drastically increasing the number of links across EKGs and therefore enhancing potential interoperability.</p> <p>Since EKG Identifiers will proliferate across the enterprise and its ecosystem and be used and stored for many years to come (could be decades) it is essential that the identifiers are always resolvable so that the need to make copies of data for long-term storage purposes decreases drastically.</p>","location":"principle/01-identity/#rationale"},{"title":"Implications","text":"<ul> <li>There should be a mapping or service to resolve other identifiers such as names, keys or other IRIs to the EKG/IRI.</li> <li>Since it is immutable, the EKG/IRI will have to be opaque i.e. not be a human-readable   since even human names, company names, customer numbers, Social Security Numbers can change over time.</li> <li>Objects that already have a well-established RDF compliant and Linked Data compliant identifier   may not necessarily need an additional EKG/IRI.   In fact, they may already have one that is external to the company's EKG.   It is in many cases recommended to even give those well-established objects, from well-established external   datasets, an EKG/IRI of your own enterprise as well for various reasons.   Examples of such objects are Legal Entity Identifiers (LEIs) and Financial Instrument Global Identifiers (FIGIs).   The EKGF will maintain a list of these for convenience.</li> <li>The use of multiple EKG identifiers---often in combination with multiple \"legacy identifiers\"---generally means   that an EKG should not use the Unique Name Assumption (UNA) (where the use of a different identifier would   imply a different object).</li> </ul>","location":"principle/01-identity/#implications"},{"title":"Meaning","text":"<p>The meaning of every Data Point must be directly resolvable to a machine-readable definition in verifiable formal logic.</p>  <p>A Data Point combines an object---using its Enterprise Knowledge Graph  IRI (EKG/IRI) as its  identifier---with the value of a property in some context. Hence, data is expressed at its most granular level for both data-at-rest and data-in-motion.</p> <p>The property itself is always an IRI---often called predicate IRI---that  refers to an object1 that represents \"the meaning\" of the given Data Point. This object has its own identity and is defined through further properties based on logic that allow information to be rigorously combined, queried and inferred. These properties that define properties---also called \"axioms\"---are standardized by means of the Web Ontology Language (OWL)  by the World Wide Web Consortium (W3C) and are grouped into \"OWL ontologies\" for management purposes.</p>","location":"principle/02-meaning/"},{"title":"Rationale","text":"<p>Expressing data at a granular level allows ultimate flexibility for it to be  sliced, diced, combined and aggregated. This capability to combine and infer information is further enhanced by the use of  property definitions built on logic. Having the properties themselves be objects that can be looked up means that all data is self-defining and carries its meaning with it. Since the information is self-defining there is no fixed schema for the EKG as a whole and it can non-disruptively incorporate additional knowledge.</p>","location":"principle/02-meaning/#rationale"},{"title":"Implications","text":"<p>Some further discovery, with subject matter experts and creators of source systems,  is often needed to truly understand what a given set of data really means and what can be inferred from it. In other words you cannot rely on the name of a column in a spreadsheet. A deceptively simple column name such as \"number of European customers\" leaves open the meaning of \"European\" and \"customer\" and timing (when does one start and stop being a customer?). And different sources could have different interpretations of that same name. The benefit is consistency, accuracy and the ability to make sound business decisions.</p>","location":"principle/02-meaning/#implications"},{"title":"Advanced","text":"<p>At higher levels of EKG/Platform maturity (level 4 and 5 to be exact) the term  \"Data Point\" may in fact become a more complex data structure that is used  \"on the wire\" that represents the Data Point at a more \"holistic\" level,  profoundly supporting Multiple Versions of the Truth (MVOT).</p> <p>Since an EKG supports many datasets that have overlapping information coming from  multiple sources, there could be:</p> <ol> <li>multiple EKG identifiers (\\glspl{ekg:iri}) for the same object</li> <li>One object can have multiple identifiers that can be linked together2 and       therefore be rightfully addressable with any of these identifiers.</li> <li>multiple definitions of meaning<ul> <li>One property of an object can have multiple definitions of meaning, for instance    \"legal name\" can be defined in multiple ontologies and be semantically equivalent3    or one property can be defined as a sub-property of another but broader semantic definition4.</li> </ul> </li> <li>multiple equal or different values coming from multiple sources</li> <li>multiple versions over time of those values (temporality)</li> </ol> <p>For each of these four \"axes\"---identity, meaning, source, and temporality---you could have multiple options to choose from even while logically, from a user perspective, it's the same data point.</p> <p>Advanced client applications, services or AIs can use these Data Points to perform last-minute \"at the edge\" computations around finding the right value from the right timeline and source with the right quality for the given context.</p>   <ol> <li> <p>the official term in the W3C RDF standard for this object is \"resource\"\u00a0\u21a9</p> </li> <li> <p>for instance via <code>owl:sameAs</code> i.e. \"Individual Equality\"\u00a0\u21a9</p> </li> <li> <p>See Equivalent Object Properties   or Equivalent Data Properties \u21a9</p> </li> <li> <p>See Data Subproperties \u21a9</p> </li> </ol>","location":"principle/02-meaning/#advanced"},{"title":"Distributed","text":"<p>Data Points for any object may be stored in many physical stores. Any access point provides connectivity to all EKG content regardless of where it resides.</p>  <p>The physical stores could include traditional databases as well as varied  EKG/Platforms specifically designed for hosting EKGs.  And some which may be hosted outside the enterprise including by information  services or governments.  All seamlessly accessed using W3C (internet-based) protocols which also allow  for browser or API linked data traversal and query.</p>","location":"principle/03-distributed/"},{"title":"Rationale","text":"<p>Federating different systems allows the knowledge available to an enterprise  to be accessed as a whole. It allows best of breed systems to be used for specific purposes,  and evolved over time without disrupting the EKG as a whole. It allows scalability through adding new hardware, swapping out systems,  and optimizing access through moving data closer to where it needs to be processed.</p>","location":"principle/03-distributed/#rationale"},{"title":"Implications","text":"<p>The potential for a loose and evolving nature does mean some degree of monitoring of  access patterns and performance; and service level agreements for vital information access.</p>","location":"principle/03-distributed/#implications"},{"title":"Open World","text":"<p>Information can vary over time, come from many internal and external sources, and be based on different identifiers and models. These multiple versions of the truth (MVOT) need to be reconciled on access by context.</p>  <p>Different sources might not always be consistent about the same Data Point.  And that may be legitimate for various business, geographical, privacy, legal or timing reasons.  Rather than try to force everything into a single overruling set of facts,  an EKG allows them to coexist, with the access context used to make  coherent selections which are consistent within themselves. In order to make those selections multiple people and systems must have transparent access  to all facts (including source, identity, meaning and value-at-time information) about all objects. Machine-executable business rules may be used at query time to join instances of data and establish quality rankings.</p>","location":"principle/04-open-world/"},{"title":"Rationale","text":"<p>This approach allows the EKG to represent the sometimes messy reality, which encompasses  not only a variety of different organizations and systems within the enterprise, but also external sources.</p>","location":"principle/04-open-world/#rationale"},{"title":"Implications","text":"<p>Attention needs to be paid to maintaining sufficient context with each data set,  and considering what is needed for each data usage use case or context, including quality.</p>","location":"principle/04-open-world/#implications"},{"title":"Self-describing","text":"<p>An EKG is composed of a set of self-describing datasets (SDDs) that provide information about lineage, provenance, pedigree, maturity, quality, licensing and governance.</p>  <p>As specified in principle 2, the properties in each Data Point are  linked to their definition so the meaning is not in doubt.  A dataset definition supplements this with management information such as its pedigree (how/when  was it derived/sourced?) and its provenance (where/who did it come from?).  This applies whether the information is maintained in the EKG itself or accessed/loaded  from existing enterprise systems (data at rest); or received as data streams/messages (data-in-motion).</p>","location":"principle/05-self-describing/"},{"title":"Rationale","text":"<p>This information is essential for data selection, enforcing policy and management of  the ecosystem as a whole. As well as being essential for management, the definitions taken together comprise a  knowledge catalog for the content of the EKG.</p>","location":"principle/05-self-describing/#rationale"},{"title":"Implications","text":"<p>The information needs to be maintained and made available on an ongoing basis. It also needs to be sought out for external sourced data, whether accessed in place or loaded into an EKG platform.</p>","location":"principle/05-self-describing/#implications"},{"title":"Measurement","text":"<p>The quality and characteristics of the managed knowledge must be measurable and measured. Measurement criteria are used to designate fitness-for-defined-purpose and must be actionable.</p>  <p>Quality comprises multiple dimensions including accuracy, timeliness, completeness, relevance,  conformity, integrity.  EKG technology allows greater power and flexibility for expressing quality rules and metrics,  but existing data quality tooling could also be used.</p>","location":"principle/06-measurement/"},{"title":"Rationale","text":"<p>This information is needed to allow the right information to be used for each use case.</p>","location":"principle/06-measurement/#rationale"},{"title":"Implication","text":"<p>The information needs to be maintained and made available on an ongoing basis.</p>","location":"principle/06-measurement/#implication"},{"title":"Business Orientation","text":"<p>All information in the EKG, and associated artifacts, are linked to defined and prioritized use cases. Nothing in the EKG exists without a known business justification and purpose.</p>  <p>An EKG use case encompasses a business narrative and outcome with a clear description as to which exact business capability is supported, expressed in business terms and links  to relevant data stories, personas, business concepts, ontologies, vocabularies,  taxonomies, datasets, workflows, user experience models, life-cycle model, deployment model, backlog, test scenarios, quality metrics, benchmark metrics, success definitions, performance indicators and other details.</p> <p>Importantly, the use cases for an EKG can make use of lower level use cases,  thus forming a so-called use case tree, though it is not a strict hierarchy  since common use cases can be reusable.  At an implementation level a use case may be associated with \"user stories\" or  \"data stories\" that form the points of interaction with end users or client systems. The vision is that a fully fleshed out and implemented use case can be deployed  as a reusable component.</p>","location":"principle/07-business-orientation/"},{"title":"Rationale","text":"<p>Use cases anchor the EKG to real business needs, and allow it to  evolve incrementally while delivering business value.  Without this, the tendency is often to focus on information modeling for its own sake,  without a focus or rationale for what to include or exclude. The use cases provide the basis for associating users with EKG functionality  and provide the context for information selection.</p>","location":"principle/07-business-orientation/#rationale"},{"title":"Implications","text":"<p>The use cases themselves need to be developed and managed as part of the  EKG development method,  and ideally as part of the EKG itself.</p>","location":"principle/07-business-orientation/#implications"},{"title":"Control","text":"<p>Entitlement, privacy and business policies will be modeled in the EKG and automatically executed, enforced and audited at the Data Point level.</p>  <p>The EKG can use enterprise and organization knowledge to express  access not only in terms of access control lists, but in terms of  business rules, policies, logic and information content. </p>","location":"principle/08-control/"},{"title":"Rationale","text":"<p>Use of the EKG itself to control and enforce access allows  more power and conciseness of policy expression and execution  while linking to existing enterprise directories.</p>","location":"principle/08-control/#rationale"},{"title":"Implications","text":"<p>Appropriate enterprise directories should be integrated in the EKG. It can take some thought to design what the policies should be at  the business level.</p>","location":"principle/08-control/#implications"},{"title":"Ecosystem","text":"<p>An enterprise will use a heterogeneous set of technologies and data sources which will be incorporated into the EKG over time. All data entering the ecosystem are subject to service level agreements.</p>  <p>A true EKG is a federation of multiple data-sources and systems  both within and external to the enterprise; seamlessly knitted together with  standard protocols and APIs. An EKG needs to be managed and evolved as a fairly complex system of systems.  To provide the flexibility and agility needed, its management needs to be automated,  and linked to development processes, through the discipline of data operations.</p>","location":"principle/09-ecosystem/"},{"title":"Rationale","text":"<p>As an ecosystem, an EKG can non-disruptively evolve over time in technology,  scalability and information and business needs addressed.</p>","location":"principle/09-ecosystem/#rationale"},{"title":"Implications","text":"<p>The management of the EKG needs to be planned for and resourced. It's important to coordinate with the owners of existing systems being used  to provide capability under the EKG umbrella.</p>","location":"principle/09-ecosystem/#implications"},{"title":"Standards","text":"<p>Data, ontologies, definitions and business rules should be compliant with open standards and transparent governance procedures as defined by recognized standards bodies.</p>  <p>Where necessary, the EKGF will work with relevant standards bodies or projects  to propose new standards or enhance existing ones.</p>","location":"principle/10-standards/"},{"title":"Rationale","text":"<p>It's important for enterprises to have trust in the quality,  interoperability and stability of the structures and interfaces  used in such a strategic investment as an EKG.</p> <p>It provides freedom of choice in being able to mix and match different  technologies and models, either in a federated EKG or over time.  That includes standards being able to respond to new advances in both  technology and techniques. </p>","location":"principle/10-standards/#rationale"},{"title":"Implications","text":"<p>It can sometimes take longer to work with industry partners to reach the  consensus needed for standardization, and to use change control/governance procedures. Release cycles may be phased to avoid constantly changing interfaces. In order to achieve agility some work products may be deployed on standards  that are have a provisional status---these need to be carefully identified.</p>","location":"principle/10-standards/#implications"},{"title":"Purposeful Business Themes","text":"<ul> <li> <p> Transparency</p>   <ul> <li>Scalable Traceability</li> <li>Grasping the impact of your business decisions across   the whole value chain</li> <li>Understanding Transformations</li> <li>Improve Explainability</li> <li>Communicating the Status of the Enterprise</li> </ul> <p>  Learn more</p> </li> <li> <p> Openness</p>   <ul> <li>Connect, Access, Take-up the silos</li> <li>Enable Silo Synergies</li> <li>Readable, Discoverable, Explorable</li> <li>Confront Multiple Versions of the Truth</li> <li>Challenge Assumptions</li> </ul> <p>  Learn more</p> </li> <li> <p> Sustainability</p>   <ul> <li>Economies of Scale</li> <li>Avoid duplication</li> <li>Reduce waste</li> <li>Quality &amp; Viability</li> </ul> <p>  Learn more</p> </li> <li> <p> Fairness</p>   <ul> <li>Recognition of value-chain contributors</li> <li>Less biased appreciation</li> <li>Unbiased distribution of information</li> </ul> <p>  Learn more</p> </li> <li> <p> Accountability</p>   <ul> <li>Negate the blame game</li> <li>Clarify success based on facts</li> <li>Profile of needs and wants (or duties &amp; obligations) valued, leveraged, and optimized.</li> </ul> <p>  Learn more</p> </li> <li> <p> Digital Assets</p>   <ul> <li>Turn data and knowledge into financial assets</li> <li>Apply Accountancy Methods Knowledge</li> <li>Deal with data products, data services &amp; data markets</li> <li>Create digital value propositions</li> </ul> <p>  Learn more</p> </li> <li> <p> Composable Business</p>   <ul> <li>Composable Business Identity</li> <li>Model-driven Business</li> <li>Replicable Modularity</li> </ul> <p>  Learn more</p> </li> <li> <p> Environmental Sustainability</p>   <ul> <li>Insight in environmental footprint </li> <li>Environmental Accountability across all infrastructures and all supply chains</li> <li>Optimize your value chain</li> </ul> <p>  Learn more</p> </li> <li> <p> Contextual Truth</p>   <ul> <li>Dialogue with the truth</li> <li>Consider all the (re)sources</li> <li>Last-minute contextual computation based on all assessed information sources</li> <li>Test your assumptions with empirical data</li> </ul> <p>  Learn more</p> </li> <li> <p> Reusability</p>   <ul> <li>Enable Economies of Scale</li> <li>Legal, Operational, Semantic and Technical Interoperability</li> <li>Design for Replicability and Reusability</li> </ul> <p>  Learn more</p> </li> <li> <p> Manage Risk &amp; Compliance</p>   <ul> <li>Measure Controls</li> <li>Aggregate impact of Risk</li> <li>Track Performance</li> <li>Assess Conformance</li> <li>Sanction Decisions</li> <li>High-resolution Due Diligence</li> </ul> <p>  Learn more</p> </li> <li> <p> Resilience</p>   <ul> <li>Ensures mission-critical operations</li> <li>Technical &amp; Business Resilience</li> <li>Business Continuity &amp; Disaster Recovery</li> <li>Pro-active mitigation of the impact of change</li> <li>Quickly recompose your business</li> </ul> <p>  Learn more</p> </li> <li> <p> Power of Abstraction</p>   <ul> <li>Infinite Zooming, understand all perspectives, Holistically &amp; Precise</li> <li>Understand the forest &amp; the trees (and the elephant in the room)</li> <li>Contextually powered abstraction</li> <li>Separation of Concerns</li> <li>Full interoperability across the conceptual space</li> </ul> <p>  Learn more</p> </li> <li> <p> Competitive Advantage</p>   <ul> <li>Innovation</li> <li>Knowing your markets, products and customers</li> <li>Optimize affordability</li> <li>Increase agility (and speed)</li> <li>Optimize economies of scale</li> </ul> <p>  Learn more</p> </li> <li> <p> Manage Profitability</p>   <ul> <li>Manage investment effectively</li> <li>Manage Business Development</li> <li>Convert data into an asset</li> <li>Reduce cost of integrations</li> <li>Optimize Value Chains</li> </ul> <p>  Learn more</p> </li> </ul>","location":"theme/"},{"title":"Accountability","text":"<ul> <li>Negate the blame game</li> <li>Clarify success based on facts</li> <li>Profile of needs and wants (or duties &amp; obligations) valued, leveraged, and optimized.</li> </ul>","location":"theme/accountability/"},{"title":"Competitive Advantage","text":"<ul> <li>Innovation</li> <li>Knowing your markets, products and customers</li> <li>Optimize affordability</li> <li>Increase agility (and speed)</li> <li>Optimize economies of scale</li> </ul>","location":"theme/competitive-advantage/"},{"title":"Composable Business","text":"<ul> <li>Composable Business Identity</li> <li>Model-driven Business</li> <li>Replicable Modularity</li> </ul>","location":"theme/composable-business/"},{"title":"Contextual Truth","text":"<ul> <li>Dialogue with the truth</li> <li>Consider all the (re)sources</li> <li>Last-minute contextual computation based on all assessed information sources</li> <li>Test your assumptions with empirical data</li> </ul>","location":"theme/contextual-truth/"},{"title":"Digital Assets","text":"<ul> <li>Turn data and knowledge into financial assets</li> <li>Apply Accountancy Methods Knowledge</li> <li>Deal with data products, data services &amp; data markets</li> <li>Create digital value propositions</li> </ul>","location":"theme/digital-assets/"},{"title":"Environmental Sustainability","text":"<ul> <li>Insight in environmental footprint </li> <li>Environmental Accountability across all infrastructures and all supply chains</li> <li>Optimize your value chain</li> </ul>","location":"theme/environmental-sustainability/"},{"title":"Fairness","text":"<ul> <li>Recognition of value-chain contributors</li> <li>Less biased appreciation</li> <li>Unbiased distribution of information</li> </ul>","location":"theme/fairness/"},{"title":"Manage Profitability","text":"<ul> <li>Manage investment effectively</li> <li>Manage Business Development</li> <li>Convert data into an asset</li> <li>Reduce cost of integrations</li> <li>Optimize Value Chains</li> </ul>","location":"theme/manage-profitability/"},{"title":"Manage Risk &amp; Compliance","text":"<ul> <li>Measure Controls</li> <li>Aggregate impact of Risk</li> <li>Track Performance</li> <li>Assess Conformance</li> <li>Sanction Decisions</li> <li>High-resolution Due Diligence</li> </ul>","location":"theme/manage-risk-and-compliance/"},{"title":"Openness","text":"<ul> <li>Connect, Access, Take-up the silos</li> <li>Enable Silo Synergies</li> <li>Readable, Discoverable, Explorable</li> <li>Confront Multiple Versions of the Truth</li> <li>Challenge Assumptions</li> </ul>","location":"theme/openness/"},{"title":"Power of Abstraction","text":"<ul> <li>Infinite Zooming, understand all perspectives, Holistically &amp; Precise</li> <li>Understand the forest &amp; the trees (and the elephant in the room)</li> <li>Contextually powered abstraction</li> <li>Separation of Concerns</li> <li>Full interoperability across the conceptual space</li> </ul>","location":"theme/power-of-abstraction/"},{"title":"Resilience","text":"<ul> <li>Ensures mission-critical operations</li> <li>Technical &amp; Business Resilience</li> <li>Business Continuity &amp; Disaster Recovery</li> <li>Pro-active mitigation of the impact of change</li> <li>Quickly recompose your business</li> </ul>","location":"theme/resilience/"},{"title":"Reusability","text":"<ul> <li>Enable Economies of Scale</li> <li>Legal, Operational, Semantic and Technical Interoperability</li> <li>Design for Replicability and Reusability</li> </ul>","location":"theme/reusability/"},{"title":"Sustainability","text":"<ul> <li>Economies of Scale</li> <li>Avoid duplication</li> <li>Reduce waste</li> <li>Quality &amp; Viability</li> </ul>","location":"theme/sustainability/"},{"title":"Transparency","text":"<ul> <li>Scalable Traceability</li> <li>Grasping the impact of your business decisions across   the whole value chain</li> <li>Understanding Transformations</li> <li>Improve Explainability</li> <li>Communicating the Status of the Enterprise</li> </ul>","location":"theme/transparency/"},{"title":"Accountability","text":"","location":"vocab/accountability/"},{"title":"Accountability","text":"<p>Accountability in the workplace is all about setting and holding people  to a common expectation by clearly defining the company\u2019s mission and values.1</p> <p>TODO. Notes:</p> <ul> <li>Who is actually accountable for any given activity?</li> <li>Responsible Assignment Matrix, RASCI (Responsible, Accountable, Supporting, Consulted and Informed)</li> <li>\"Breeds trust\"</li> <li>\"Accountability in the workplace fuels successful organization\"</li> <li>Ties to fairness</li> </ul>    <ol> <li> <p>Why Is Accountability Important in the Workplace? \u21a9</p> </li> </ol>","location":"vocab/accountability/#accountability"},{"title":"Data retention","text":"","location":"vocab/data-retention/"},{"title":"Data retention","text":"<p>Data retention defines the policies of persistent data and records  management for meeting legal and business data archival requirements.</p>","location":"vocab/data-retention/#data-retention"},{"title":"Enterprise Knowledge Graph","text":"","location":"vocab/ekg/"},{"title":"Enterprise Knowledge Graph (EKG)","text":"<p>much like \"the web\" is a virtual concept, an Enterprise Knowledge Graph (EKG) is a virtual concept  that stands for the combination of all information and knowledge of a given enterprise -- at any level in the organization -- or ecosystem.</p> <p>See also Enterprise Knowledge Graph for a more elaborate explanation.</p>","location":"vocab/ekg/#enterprise-knowledge-graph-ekg"},{"title":"Fairness","text":"","location":"vocab/fairness/"},{"title":"Fairness","text":"<p>TODO. Notes:</p> <ul> <li>Link to FAIR data principles.</li> <li>Fairness in the workplace contributes to employees feeling    safe and engaged in the work they produce.    It creates a productive environment for employees in which   the organization compensates them fairly and management    professionals equally appreciate each employee's hard work.1</li> </ul>    <ol> <li> <p>7 Ways To Exhibit Fairness in the Workplace \u21a9</p> </li> </ol>","location":"vocab/fairness/#fairness"},{"title":"Openness","text":"","location":"vocab/openness/"},{"title":"Openness","text":"","location":"vocab/openness/#openness"},{"title":"Proportionality","text":"","location":"vocab/proportionality/"},{"title":"Proportionality","text":"<p>Quote from the document \"European Interoperability Framework, underlying Principles of European Public Services\":</p>  <p>The proportionality principle limits EU actions to what is necessary to achieve the objectives  of the Treaties.</p>  <p>Proportionality is also a principle concerning Enterprise Knowledge Graphs since what goes for the EU as a whole also goes for an enterprise or any other organization at a smaller scale:</p>  <p>The proportionality principle limits the enterprise's actions to what is  necessary to achieve the interoperability requirements that support the  strategic objectives of the enterprise.</p>  <p>In other words, give as much autonomy to each department or line of business, keep every enterprise level operation \"proportional\".</p>","location":"vocab/proportionality/#proportionality"},{"title":"Self-describing Dataset","text":"","location":"vocab/sdd/"},{"title":"Self-describing Dataset (SDD)","text":"<p>In a mature Enterprise Knowledge Graph (EKG), the information provided (or consumed) by  every connected data source (or target) can and should be described as a logical dataset that we call a self-describing dataset (SDD).1 Depending on maturity and architecture these SDDs are also known as data products or data services.</p> <p>The general idea is that everything that can be said about a given dataset should be described---as close as possible and ideally in---that dataset itself.</p> <p>Many topic areas can require such description, most of which would be described as \"policies\" in the form of models that are enforceable by EKG/Platform Services at run-time.</p>","location":"vocab/sdd/#self-describing-dataset-sdd"},{"title":"Topic Areas","text":"","location":"vocab/sdd/#topic-areas"},{"title":"Core Data-catalog information","text":"<p>Core information about the dataset.</p> <p>Ontologies:</p> <ul> <li>DCAT</li> </ul>","location":"vocab/sdd/#core-data-catalog-information"},{"title":"Meaning","text":"<p>Linkage to concepts, ontologies, taxonomies and vocabularies.</p> <p>Ontologies:</p> <ul> <li>OWL</li> <li>SKOS</li> <li>SHACL</li> </ul>","location":"vocab/sdd/#meaning"},{"title":"Identifier Policies","text":"<p>Identifier registration office, creation policies, identifier related security policies and the like.</p>","location":"vocab/sdd/#identifier-policies"},{"title":"Entitlement Policies","text":"<p>Personas, their privileges and jurisdiction-specific entitlement policies.</p>","location":"vocab/sdd/#entitlement-policies"},{"title":"Ownership / Intellectual Property","text":"","location":"vocab/sdd/#ownership-intellectual-property"},{"title":"Pedigree","text":"","location":"vocab/sdd/#pedigree"},{"title":"Provenance","text":"<ul> <li>This also unveils what \"authoritative data\" the dataset contains,   is it the \"golden copy\" and \"authoritative source\" for any given datapoint or not?</li> </ul> <p>Maturity Levels:</p> <ul> <li>Business Rules - Level 2</li> </ul>","location":"vocab/sdd/#provenance"},{"title":"Lineage","text":"","location":"vocab/sdd/#lineage"},{"title":"Transformation Policies","text":"<p>Policies that describe in detail how any given datapoint can be constructed from other datapoints whether they reside in the EKG or elsewhere.</p> <p>Used to:</p> <ul> <li>provide the detail that's necessary to build up the proper end-to-end lineage information.</li> <li>enable smart generic EKG/Platform Services or EKGOps Pipelines to transform data in a model-driven fashion </li> </ul>","location":"vocab/sdd/#transformation-policies"},{"title":"Changes","text":"","location":"vocab/sdd/#changes"},{"title":"History","text":"","location":"vocab/sdd/#history"},{"title":"Audit","text":"","location":"vocab/sdd/#audit"},{"title":"Quality Metrics and Assessments","text":"","location":"vocab/sdd/#quality-metrics-and-assessments"},{"title":"Hygiene Policies","text":"<p>Policies that describe how the overall \"hygiene\" of the dataset can be checked.</p> <p>Used to:</p> <ul> <li>enable smart generic EKG/Platform Services or EKGOps Pipelines to do a quick \"smoke test\" of the data and/or a thorough check   on all kinds of (technical) details such as data formats etc (relates to data profiling as well)</li> </ul>","location":"vocab/sdd/#hygiene-policies"},{"title":"Data Profiling Policies","text":"","location":"vocab/sdd/#data-profiling-policies"},{"title":"Source Pricing","text":"<p>In order to be able to calculate the cost of data it is useful to know---per dataset---what was paid to obtain or create the data.</p>","location":"vocab/sdd/#source-pricing"},{"title":"Usage Pricing","text":"<p>What are the pricing options for users of the data.</p>","location":"vocab/sdd/#usage-pricing"},{"title":"Usage Agreement Policies / Service Level Agreements","text":"<p>Dataset-specific service level agreements or policies to create such agreements.</p>","location":"vocab/sdd/#usage-agreement-policies-service-level-agreements"},{"title":"Usage Metric Collection Policies","text":"<p>How is the data used and how are usage metrics collected and is that mandatory or optional, depending on the Usage Agreement Policy.</p>","location":"vocab/sdd/#usage-metric-collection-policies"},{"title":"Revenue","text":"<p>Revenue can be determined in multiple ways, ideally all usage of all data covered by the SDD is priced and charged for (see pricing policies and usage metrics) which would make the revenue computation very easy but usually data is not priced (because there is no infrastructure and priority for it) so the calculation of the value of the data becomes much more complicated and can only be derived from the position of the dataset in the context of the larger data supply chain.</p>","location":"vocab/sdd/#revenue"},{"title":"Cost","text":"<p>E.g. cost of creation, maintenance, \"cost of data\".</p>","location":"vocab/sdd/#cost"},{"title":"Value","text":"<p>Revenue minus cost.</p>","location":"vocab/sdd/#value"},{"title":"Data supply-chain","text":"<p>E.g. in which processes, use cases, LOBs is the data used and deemed to be critical.</p> <p>Used to:</p> <ul> <li>determine the value of data</li> <li>determine what the criticality is of the data (for regulatory, risk and business continuation purposes)</li> <li>determine whether alternative sources may be available</li> <li>determine whether business processes could be improved</li> </ul>","location":"vocab/sdd/#data-supply-chain"},{"title":"Classification","text":"<p>E.g. security classification, PII data, confidentiality, criticality, per context/use case.</p>","location":"vocab/sdd/#classification"},{"title":"Data Life Cycle","text":"<p>Ontologies:</p> <ul> <li>DCAT</li> </ul>","location":"vocab/sdd/#data-life-cycle"},{"title":"Temporality Policies","text":"<p>How is temporality being dealt with, which parts of the dataset are just reflecting the \"current state\" and which parts are historic (or future / \"what if\") data? And which design patterns are used to maintain temporality? Smart model-driven EKG/Platform services can then a) maintain temporality and b) use it properly.</p>","location":"vocab/sdd/#temporality-policies"},{"title":"Data Retention &amp; Archiving Policies","text":"","location":"vocab/sdd/#data-retention-archiving-policies"},{"title":"Physical Dataset Policies","text":"<p>Given the logical dataset---the SDD---which physical manifestations does it have, what types, which ones are allowable etc.</p> <p>For instance, one SDD produced overnight by a batch-job, stored as an RDF file in an S3 bucket, may be loaded into different databases of different types at different locations.</p> <p>In the context of a more mature EKG platform, smart services may wish to control the proliferation of data in all its various manifestations across the enterprise and enforce policies.</p>","location":"vocab/sdd/#physical-dataset-policies"},{"title":"Logging Policies","text":"<p>E.g. which data may or may not appear in logs or only in obfuscated form.</p>","location":"vocab/sdd/#logging-policies"},{"title":"Obfuscation / Masking Policies","text":"<p>Depending on entitlement policies, which datapoints are so critical that they can only be seen in obfuscated or masked form by certain personas in certain use-cases?</p> <p>How does the actual obfuscation or masking take place, what are the technical mechanisms used for which particular datapoints? (encryption, hashing, which fields are randomized etc).</p> <p>Used to:</p> <ul> <li>ensure that no confidential data appears in any logging or   monitoring systems and the like.</li> <li>ensure that proper obfuscation or masking policies are enforced when   generating test datasets.</li> <li>ensure that, even in production, only entitled personas (see entitlement policies)   can see the non-obfuscated versions of certain datapoints.</li> <li>make it possible that obfuscated versions of datapoints may be part of larger objects   seen by certain personas in certain use cases without having to leave those datapoints   out of the picture altogether.</li> </ul> <p>TODO: Add a side-box about \"computations over encrypted data\" (see also Encryption Policies)</p>","location":"vocab/sdd/#obfuscation-masking-policies"},{"title":"Test Data Policies","text":"<p>Policies to create test-datasets derived from the production version of the given SDD.</p> <p>This is not about the tests themselves, which are usually done in the context of  a use case, but more about how to create realistic test-data in the first place.</p> <ul> <li>Even for public datasets, especially if they are very large, it may be useful to have   a policy (model) for the creation of a subset of the data that can realistically be used   for testing purposes that contains all the relevant edge cases.</li> <li>For confidential data, masking policies or obfuscation policies   may come into play.</li> <li>Goal is to have smart EKG/Platform Services that generate test data on demand for    DEV/TEST/UAT environments. </li> </ul>","location":"vocab/sdd/#test-data-policies"},{"title":"Query &amp; Search Policies","text":"<p>E.g. which methods are supported for advanced queries or search requests.</p>","location":"vocab/sdd/#query-search-policies"},{"title":"Inference Policies","text":"<p>E.g. what are the recommended/mandatory instructions for inference engines.</p> <p>Used to:</p> <ul> <li>determine whether it is mandatory to host the SDD in an environment where a given type of inference engine is available.<ul> <li>datasets with datapoints that are tied to OWL ontologies that are heavily relying on reasoning</li> <li>requires OWL-DL or OWL-RL etc</li> <li>is designed to run with reasoning with multiple schemas (see for instance     Stardog's Reasoning with Multiple Schemas)</li> <li>requires to be loaded in a triplestore product that supports forward chaining (i.e. Ontotext GraphDb)     or backward chaining (i.e. Stardog)</li> </ul> </li> </ul>","location":"vocab/sdd/#inference-policies"},{"title":"Caching Policies","text":"<p>E.g. how long can any given datapoint reside in a cache such as an HTTP proxy etc.</p> <p>Used to:</p> <ul> <li>create architectures that heavily rely on caching to improve performance</li> <li>inform SPARQL query developers about their options to cache the results of any given SPARQL statement (since SPARQL is    an HTTP protocol its quite natural to leverage the standard HTTP caching facilities)</li> <li>enable smart caching services to automatically flush stale entries from their caches intelligently</li> <li>ensure that data retention policies are also enforced by making    sure that certain datapoints do not stick around in long-term caches and content delivery networks etc.</li> </ul>","location":"vocab/sdd/#caching-policies"},{"title":"Encryption Policies","text":"","location":"vocab/sdd/#encryption-policies"},{"title":"Governance Policies","text":"","location":"vocab/sdd/#governance-policies"},{"title":"Issue Management Policies","text":"","location":"vocab/sdd/#issue-management-policies"},{"title":"Change Management Policies","text":"","location":"vocab/sdd/#change-management-policies"},{"title":"Funding Policies","text":"<p>E.g. which datapoints can only be retrieved in encrypted form or could be used in encrypted form by certain computations.</p>  <p>Note</p> <p>Note that this list of topic areas does not include \"use cases\" since use cases are assumed to  be defined elsewhere (in fact, in their own datasets) where the use case links to the dataset but  not vice versa because each self-describing dataset is assumed to be designed and developed  independently from any given use case. Self-describing datasets are \"use case agnostic\" and as  much as possible \"unbiased\", supporting existing use cases and any number of unknown future  use cases.</p>    <ol> <li> <p>See also the Capability Datasets in the Maturity Model for the EKG \u21a9</p> </li> </ol>","location":"vocab/sdd/#funding-policies"},{"title":"Subsidiarity","text":"","location":"vocab/subsidiarity/"},{"title":"Subsidiarity","text":"<p>Quote from the document \"European Interoperability Framework, underlying Principles of European Public Services\":</p>  <p>The subsidiarity principle requires EU decisions to be taken as closely as possible  to  the  citizen.  In  other  words,  the  EU  does  not  take  action  unless  this  is  more  effective  than  the  same  action  taken  at  national  level.</p>","location":"vocab/subsidiarity/#subsidiarity"},{"title":"Sustainability","text":"","location":"vocab/sustainability/"},{"title":"Sustainability","text":"","location":"vocab/sustainability/#sustainability"},{"title":"Transparency","text":"","location":"vocab/transparency/"},{"title":"Transparency","text":"<p>TODO. Notes:</p> <ul> <li>Explainability of AI decisions (or any decision)</li> <li>Provenance/Lineage/Pedigree, where do \"facts\" come from and how do/did they affect decisions?</li> <li>Who is adding which value where? Links to appraisal accountability etc</li> <li>Financial integrity</li> </ul> <p>See also openness.</p>","location":"vocab/transparency/#transparency"},{"title":"Use Case Tree","text":"","location":"vocab/use-case-tree/"},{"title":"Use Case Tree (UCT)","text":"<p>See Use Case Tree</p>","location":"vocab/use-case-tree/#use-case-tree-uct"},{"title":"Use Case","text":"","location":"vocab/use-case/"},{"title":"Use Case","text":"<p>See Use Case</p>","location":"vocab/use-case/#use-case"}]}